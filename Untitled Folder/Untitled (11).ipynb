{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fad01-40dc-4726-ac35-984aba157eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56195613-c634-405a-a824-61b740a3da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_blurring():\n",
    "    image = cv2.imread('src2.jpg')\n",
    "    img_blur = cv2.GaussianBlur(image, (11, 11), 0)\n",
    "    cv2.imwrite('img_blur.jpg', img_blur)\n",
    "Gaussian_blurring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1569c1f-f174-40a3-a9d7-4a3058cee44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mask(image):\n",
    "    T, mask_img = cv2.threshold(image, 225, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imwrite('mask_img_3.jpg', mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e071c31-99cc-43e1-a729-bc2fe2a48413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizing(img,n,m):\n",
    "    res_img = cv2.resize(img, (n, m), cv2.INTER_NEAREST)\n",
    "    cv2.imwrite('res_img.jpg', res_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e06965-e2cc-47b8-94b6-96429dbdd16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_image = cv2.imread('src2.jpg')\n",
    "#gray_main_image = cv2.cvtColor(main_image, cv2.COLOR_BGR2GRAY)\n",
    "#contours = find_mask(gray_main_image)\n",
    "find_mask(main_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cfaec-fa05-4b28-b66a-61557f77de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    " img = cv2.imread(\"img_blur2.jpg\", 0)\n",
    " # Рассчитать минимальный уровень серого и максимальный уровень серого, отображаемые в исходном изображении\n",
    " # Используйте функцию расчета\n",
    "Imin, Imax = cv2.minMaxLoc(img)[:2]\n",
    " # Использовать числовой расчет\n",
    "# Imax = np.max(img)\n",
    "# Imin = np.min(img)\n",
    "Omin, Omax = 0, 255\n",
    " # Рассчитать значения a и b\n",
    "a = float(Omax - Omin) / (Imax - Imin)\n",
    "b = Omin - a * Imin\n",
    "out = a * img + b\n",
    "out = out.astype(np.uint8)\n",
    "cv2.imwrite('img.jpg', out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4bfb2b-3791-4755-80c4-6c3ddd55152b",
   "metadata": {},
   "source": [
    "# Алгоритм Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af238e68-fdae-48f7-bece-6e9a0ee93290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def edge_demo(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Находим градиент по оси X\n",
    "    grad_x = cv2.Sobel(gray, cv2.CV_16SC1, 1, 0)\n",
    "    # Находим градиент в направлении y\n",
    "    grad_y = cv2.Sobel(gray, cv2.CV_16SC1, 0, 1)\n",
    "    # Преобразуем значение градиента в 8 бит\n",
    "    x_grad = cv2.convertScaleAbs(grad_x)\n",
    "    y_grad = cv2.convertScaleAbs(grad_y)\n",
    "    # Объединить два градиента\n",
    "    src1 = cv2.addWeighted(x_grad, 0.5, y_grad, 0.5, 0)\n",
    "    # Объедините градиенты, используя хитрый алгоритм, где 50 и 100 - пороги \n",
    "    edge = cv2.Canny(src1, 50, 100)\n",
    "    #cv.imshow(\"Canny_edge_1\", edge)\n",
    "    #cv.imwrite('src.jpg', edge)\n",
    "    edge1 = cv2.Canny(grad_x, grad_y, 10, 100)\n",
    "    #cv.imshow(\"Canny_edge_2\", edge1)\n",
    "    #cv.imwrite('src.jpg', edge1)\n",
    "    # Используйте край как маску для выполнения побитовых и побитовых операций\n",
    "    edge2 = cv2.bitwise_and(image+1, image+1, mask=edge1)\n",
    "    #cv.imshow(\"bitwise_and\", edge2)\n",
    "    cv2.imwrite('src.jpg', edge2)\n",
    "\n",
    "\n",
    "src = cv2.imread(\"g.jpg\")\n",
    "edge_demo(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d7716-d1dd-42c3-a95c-b796b237dd78",
   "metadata": {},
   "source": [
    "# region growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95c311-86a9-4730-8cfa-00713851dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "class Point(object):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def getX(self):\n",
    "        return self.x\n",
    "    def getY(self):\n",
    "        return self.y\n",
    "\n",
    "    \n",
    "def getGrayDiff(img,currentPoint,tmpPoint):\n",
    "    return abs(int(img[currentPoint.x,currentPoint.y]) - int(img[tmpPoint.x,tmpPoint.y]))\n",
    " \n",
    "def selectConnects(p):\n",
    "    if p != 0:\n",
    "        connects = [Point(-1, -1), Point(0, -1), Point(1, -1), Point(1, 0), Point(1, 1), \\\n",
    "                    Point(0, 1), Point(-1, 1), Point(-1, 0)]\n",
    "    else:\n",
    "        connects = [ Point(0, -1),  Point(1, 0),Point(0, 1), Point(-1, 0)]\n",
    "    return connects\n",
    " \n",
    "def regionGrow(img,seeds,thresh,p = 1):\n",
    "    height, weight = img.shape\n",
    "    seedMark = np.zeros(img.shape)\n",
    "    seedList = []\n",
    "    for seed in seeds:\n",
    "        seedList.append(seed)\n",
    "    label = 1\n",
    "    connects = selectConnects(p)\n",
    "    while(len(seedList)>0):\n",
    "        currentPoint = seedList.pop(0)\n",
    " \n",
    "        seedMark[currentPoint.x,currentPoint.y] = label\n",
    "        for i in range(8):\n",
    "            tmpX = currentPoint.x + connects[i].x\n",
    "            tmpY = currentPoint.y + connects[i].y\n",
    "            if tmpX < 0 or tmpY < 0 or tmpX >= height or tmpY >= weight:\n",
    "                continue\n",
    "            grayDiff = getGrayDiff(img,currentPoint,Point(tmpX,tmpY))\n",
    "            if grayDiff < thresh and seedMark[tmpX,tmpY] == 0:\n",
    "                seedMark[tmpX,tmpY] = label\n",
    "                seedList.append(Point(tmpX,tmpY))\n",
    "    return seedMark\n",
    "\n",
    "\n",
    "img = cv2.imread('img_blur.jpg',0)\n",
    "seeds = [Point(10,10),Point(82,150),Point(20,300)]\n",
    "binaryImg = regionGrow(img,seeds,10)\n",
    "res_img = cv2.resize(binaryImg, (1200, 900), cv2.INTER_NEAREST)\n",
    "cv2.imshow(' ',res_img)\n",
    "cv2.imwrite('binaryImg.jpg', res_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8fcac3-77e0-4777-9a64-c2d1df16b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "def convolution(image, kernel, average=False, verbose=False):\n",
    "    if len(image.shape) == 3:\n",
    "        print(\"Found 3 Channels : {}\".format(image.shape))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        print(\"Converted to Gray Channel. Size : {}\".format(image.shape))\n",
    "    else:\n",
    "        print(\"Image Shape : {}\".format(image.shape))\n",
    "\n",
    "    print(\"Kernel Shape : {}\".format(kernel.shape))\n",
    "\n",
    "    if verbose:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(\"Image\")\n",
    "        plt.show()\n",
    "\n",
    "    image_row, image_col = image.shape\n",
    "    kernel_row, kernel_col = kernel.shape\n",
    "\n",
    "    output = np.zeros(image.shape)\n",
    "\n",
    "    pad_height = int((kernel_row - 1) / 2)\n",
    "    pad_width = int((kernel_col - 1) / 2)\n",
    "\n",
    "    padded_image = np.zeros((image_row + (2 * pad_height), image_col + (2 * pad_width)))\n",
    "\n",
    "    padded_image[pad_height:padded_image.shape[0] - pad_height, pad_width:padded_image.shape[1] - pad_width] = image\n",
    "\n",
    "    if verbose:\n",
    "        plt.imshow(padded_image, cmap='gray')\n",
    "        plt.title(\"Padded Image\")\n",
    "        plt.show()\n",
    "\n",
    "    for row in range(image_row):\n",
    "        for col in range(image_col):\n",
    "            output[row, col] = np.sum(kernel * padded_image[row:row + kernel_row, col:col + kernel_col])\n",
    "            if average:\n",
    "                output[row, col] /= kernel.shape[0] * kernel.shape[1]\n",
    "\n",
    "    print(\"Output Image size : {}\".format(output.shape))\n",
    "\n",
    "    if verbose:\n",
    "        plt.imshow(output, cmap='gray')\n",
    "        \n",
    "        plt.title(\"Output Image using {}X{} Kernel\".format(kernel_row, kernel_col))\n",
    "        Imin, Imax = cv2.minMaxLoc(output)[:2]\n",
    "        Omin, Omax = 0, 255\n",
    "         # Рассчитать значения a и b\n",
    "        a = float(Omax - Omin) / (Imax - Imin)\n",
    "        b = Omin - a * Imin\n",
    "        out = a * output + b\n",
    "        out = out.astype(np.uint8)\n",
    "        cv2.imwrite('img_blur2.jpg', out)\n",
    "        plt.show()\n",
    "\n",
    "    return output\n",
    "\n",
    "def dnorm(x, mu, sd):\n",
    "    return 1 / (np.sqrt(2 * np.pi) * sd) * np.e ** (-np.power((x - mu) / sd, 2) / 2)\n",
    "\n",
    "\n",
    "def gaussian_kernel(size, sigma=1, verbose=False):\n",
    "    kernel_1D = np.linspace(-(size // 2), size // 2, size)\n",
    "    for i in range(size):\n",
    "        kernel_1D[i] = dnorm(kernel_1D[i], 0, sigma)\n",
    "    kernel_2D = np.outer(kernel_1D.T, kernel_1D.T)\n",
    "    kernel_2D *= 1.0 / kernel_2D.max()\n",
    "    if verbose:\n",
    "        plt.imshow(kernel_2D, interpolation='none', cmap='gray')\n",
    "        plt.title(\"Kernel ( {}X{} )\".format(size, size))\n",
    "        plt.show()\n",
    "\n",
    "    return kernel_2D\n",
    "\n",
    "\n",
    "def gaussian_blur(image, kernel_size, verbose=False):\n",
    "    kernel = gaussian_kernel(kernel_size, sigma=math.sqrt(kernel_size), verbose=verbose)\n",
    "    return convolution(image, kernel, average=True, verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "image = cv2.imread(\"4.jpg\")\n",
    "res_img = cv2.resize(image, (800, 400), cv2.INTER_NEAREST)\n",
    "gaussian_blur(res_img, 17, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b4198-3bf6-4057-a536-be9379cfadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from PIL import Image\n",
    "\n",
    "def median_filter(data, filter_size):\n",
    "    temp = []\n",
    "    indexer = filter_size // 2\n",
    "    data_final = []\n",
    "    data_final = numpy.zeros((len(data),len(data[0])))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            for z in range(filter_size):\n",
    "                if i + z - indexer < 0 or i + z - indexer > len(data) - 1:\n",
    "                    for c in range(filter_size):\n",
    "                        temp.append(0)\n",
    "                else:\n",
    "                    if j + z - indexer < 0 or j + indexer > len(data[0]) - 1:\n",
    "                        temp.append(0)\n",
    "                    else:\n",
    "                        for k in range(filter_size):\n",
    "                            temp.append(data[i + z - indexer][j + k - indexer])\n",
    "\n",
    "            temp.sort()\n",
    "            data_final[i][j] = temp[len(temp) // 2]\n",
    "            temp = []\n",
    "    return data_final\n",
    "\n",
    "\n",
    "def main():\n",
    "    img = Image.open(\"4.jpg\").convert(\"L\")\n",
    "    arr = numpy.array(img)\n",
    "    removed_noise = median_filter(arr, 17) \n",
    "    img = Image.fromarray(removed_noise)\n",
    "    img.show()\n",
    "    img=img.convert(\"L\")\n",
    "    img.save('img_blur3.jpg')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f9991-a31a-43e8-a132-f6888673a7d2",
   "metadata": {},
   "source": [
    "# COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8c5c3-cbb4-4b27-9796-f37f3dbd037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import morphology\n",
    "def fill_color_demo(image):\n",
    "    copyImg = image.copy()\n",
    "    h, w = image.shape[:2]\n",
    "    mask = np.zeros ([h + 2, w + 2], np.uint8) # маска должна добавить 2 для строк и столбцов и должна быть одноканальным массивом uint8\n",
    "         # Почему сложение 2 можно понять следующим образом: когда сканирование потока начинается с 0 строк и 0 столбцов, дополнительные 2 в маске могут обеспечить обработку пикселей на границе сканирования.\n",
    "    cv2.floodFill(copyImg, mask, (0, 0), (0, 0, 0), (100, 100, 100), (50, 50 ,50), cv2.FLOODFILL_FIXED_RANGE)\n",
    "    return copyImg\n",
    "    #cv2.imwrite('src1.jpg', copyImg)\n",
    "im = cv2.imread('4.jpg')\n",
    "#im = cv2.resize(im, (2048,1365), cv2.INTER_NEAREST)\n",
    "morph = im.copy()\n",
    "#сглаживание изображения с альтернативным закрытием и открытием с увеличивающимся ядром\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1)) #Возвращает структурирующий элемент указанного размера и формы для морфологических операций.\n",
    "#MORPH_RECT - форма структурирующего элемента,прямоугольный структурирующий элемент:E_ij=1\n",
    "morph = cv2.morphologyEx(morph, cv2.MORPH_CLOSE, kernel) #Выполняет расширенные морфологические преобразования.\n",
    "morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "gradient_image = cv2.morphologyEx(morph, cv2.MORPH_GRADIENT, kernel) #морфологический градиент\n",
    "image_channels = np.split(np.asarray(gradient_image), 3, axis=2)#разделение градиентного изображения на каналы\n",
    "\n",
    "channel_height, channel_width, _ = image_channels[0].shape\n",
    "\n",
    "#применение порогового значения Оцу к каждому каналу\n",
    "for i in range(0, 3):\n",
    "    _, image_channels[i] = cv2.threshold(~image_channels[i], 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n",
    "    image_channels[i] = np.reshape(image_channels[i], newshape=(channel_height, channel_width, 1))\n",
    "\n",
    "image_channels = np.concatenate((image_channels[0], image_channels[1], image_channels[2]), axis=2) #обьединение каналов\n",
    "\n",
    "#cv2.imwrite('src1.jpg', image_channels) # сохранение картинки без шумов\n",
    "#src = cv2.imread('src1.jpg')\n",
    "img=fill_color_demo(image_channels)\n",
    "h, w = im.shape[:2]\n",
    "w=w*0.1\n",
    "# считать изображение, изменяя его в оттенках серого, бинаризировать, затем удалить небольшие скопления пикселей\n",
    "def cleaning(im):\n",
    "    grayscale = skimage.color.rgb2gray(im)\n",
    "    binarized = np.where(grayscale>0.1, 1, 0)\n",
    "    processed = morphology.remove_small_objects(binarized.astype(bool), min_size=w, connectivity=1).astype(int)\n",
    "    # затемнение пикселей\n",
    "    mask_x, mask_y = np.where(processed == 0)\n",
    "    mask_x1,mask_y1= np.where(processed != 0)\n",
    "    #im[mask_x1, mask_y1, :3] = 255\n",
    "    #im[mask_x, mask_y, :3] = 0\n",
    "    im[mask_x1, mask_y1] = 255\n",
    "    im[mask_x, mask_y] = 0\n",
    "    #cv2.imwrite('clean.jpg', im)\n",
    "    return im\n",
    "    \n",
    "#name='src2.jpg'\n",
    "im=cleaning(img)\n",
    "im= cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im = cv2.threshold(im, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "num_labels, labels_im = cv2.connectedComponents(im)\n",
    "def imshow_components(labels):\n",
    "    # Сопоставление метки компонентов со значениями оттенков\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue) #Возвращает массив единиц с той же формой и типом, что и данный массив.\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2RGB)#CVT В RGB\n",
    "    labeled_img[label_hue==0] = 0 #фон в чрный\n",
    "    #cv2.imwrite('src3.jpg', labeled_img)\n",
    "    na = np.array(labeled_img)\n",
    "    colours, counts = np.unique(na.reshape(-1,3), axis=0, return_counts=1)\n",
    "    colours=colours.tolist();\n",
    "    counts=counts.tolist();\n",
    "    colours1=[]\n",
    "    counts1=[]\n",
    "    only1=[]\n",
    "    for i in range(1,len(counts)):\n",
    "        if (counts[i]>w):\n",
    "            counts1.append(counts[i])\n",
    "            colours1.append(colours[i])\n",
    "    colours1=np.asarray(colours1)\n",
    "    for i in range(1,len(colours1)):\n",
    "        only = cv2.inRange(labeled_img, colours1[i], colours1[i])\n",
    "        only1.append(only)\n",
    "        #name = \"photo\"+str(i)+\".jpg\"\n",
    "        #cv2.imwrite(name, only)\n",
    "    return only1,len(counts)\n",
    "im,l=imshow_components(labels_im)\n",
    "for i in range(len(im)):\n",
    "    im[i]= cv2.cvtColor(im[i], cv2.COLOR_GRAY2BGR)\n",
    "img = cv2.imread(\"4.jpg\")#исходное фото\n",
    "#img = cv2.resize(img, (2048,1365), cv2.INTER_NEAREST)\n",
    "for i in range(len(im)):\n",
    "    #name = \"photo\"+str(i)+\".jpg\"\n",
    "    name1=\"photo___\"+str(i)+\".jpg\"\n",
    "    #im = cv2.imread(name)\n",
    "    bitwiseXor = cv2.bitwise_and(im[i],img)\n",
    "    cv2.imwrite(name1, bitwiseXor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f9b4b2-1e93-4a3f-a5d4-c884177ce8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"clean.jpg\")# фото из которого вычитаем (исходное фото)\n",
    "img2 = cv2.imread(\"clean_perfect.jpg\")# фото которое вычитаем(идеальный результат)\n",
    "\n",
    "bitwiseXor = cv2.subtract(img,img2)#вычитаем (чтоб понять, каких пикселей слишком много)\n",
    "\n",
    "#cv2.imshow(\"before subtraction\",img)\n",
    "#cv2.imshow(\"subtract this\",img2)\n",
    "\n",
    "img2 = cv2.bitwise_not(img2) #инвертируем идеальный результат\n",
    "img = cv2.bitwise_not(img) #инвертируем исходное фото\n",
    "bitwiseXor2 = cv2.subtract(img,img2)#вычитаем инверсию (чтоб понять, каких пикселей недостает)\n",
    "\n",
    "\n",
    "#cv2.imshow(\"after subtraction (unnecessary pixels)\",bitwiseXor)\n",
    "#cv2.imshow(\"after subtraction inv (missing pixels)\",bitwiseXor2)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "nozero = bitwiseXor[bitwiseXor > 0]#считаем все не черные пиксели\n",
    "nozero2 = bitwiseXor2[bitwiseXor2 > 0]#считаем все не черные пиксели\n",
    "print(\"Лишних пикселей:\", (len(nozero))/72000000 ,\"; недостает пикселей\", (len(nozero2))/72000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385eb5d9-9fdc-445f-b4ef-5587f7b2b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "a = [42.68933472222222,7.730329166666666,3.368815277777778,2.7363027777777778,1.7471986111111112,1.4283125,1.2762375,1.2607791666666666,1.0854416666666667]\n",
    "bi = np.array([0, 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4])\n",
    "width=0.1\n",
    "b = [1.3971736111111112,1.2590263888888889,1.3029277777777779,1.3141694444444444,1.3494319444444444,1.3781680555555556,1.3908722222222222,1.3968638888888888,1.4267722222222222]\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "plt.bar(bi, a, width)\n",
    "plt.bar(bi+0.1, b, width)\n",
    "plt.xticks(bi, [\"0\", \"0.1\", \"0.5\", \"1\", \"5\", \"10\",\"13\",\"14\", \"20\"])\n",
    "plt.legend([\"Лишние пиксели\", \"Недостающие пиксели\"])\n",
    "plt.xlabel(\"Кол-во пикселей от ширины в %\")\n",
    "plt.ylabel(\"л/п и л/о оценка в %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a502823-4919-4236-9bf5-c6583e616062",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.bar(bi, a, width)\n",
    "plt.xticks(bi, [\"0\", \"0.1\", \"0.5\", \"1\", \"5\", \"10\",\"13\",\"14\", \"20\"])\n",
    "plt.xlabel(\"Кол-во пикселей от ширины в %\")\n",
    "plt.ylabel(\"л/п оценка в %\")\n",
    "plt.legend([\"Лишние пиксели\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56363dd-cb08-49b2-bb38-6cc0e096075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.bar(bi, b, width,color=\"orange\")\n",
    "plt.xticks(bi, [\"0\", \"0.1\", \"0.5\", \"1\", \"5\", \"10\",\"13\",\"14\", \"20\"])\n",
    "plt.xlabel(\"Кол-во пикселей от ширины в %\")\n",
    "plt.ylabel(\"л/о оценка в %\")\n",
    "plt.legend([\"Недостающие пиксели\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc70500-ea89-44a6-a50c-ef805b2e9604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
